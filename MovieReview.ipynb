{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MovieReview.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO1DaRASL0J8pkmhpNpLI6x",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Angeal13/RNN_MovieReview/blob/master/MovieReview.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Y16fCAlJQup",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 2.x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zmpyvf09JUmq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fecee2eb-ca42-4be7-86c2-c25fee58df8c"
      },
      "source": [
        "from keras.datasets import imdb\n",
        "from keras.preprocessing import sequence\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import numpy as np"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9k33vaUVJr3O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Give numbers to the amount of words that will be used, max size on words per, and the Batch Size\n",
        "VOCAB_SIZE=88584\n",
        "MAXLEN=250\n",
        "BATCH_SIZE=64"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SEgCQCBWJ2fU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "18f02d4d-541c-456f-c50f-1b8e4453af1e"
      },
      "source": [
        "#Separate the Training and Tasting data\n",
        "(train_data,train_labels),(test_data,test_labels)=imdb.load_data(num_words=VOCAB_SIZE)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/text-datasets/imdb.npz\n",
            "17465344/17464789 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Up1AL1RDJ1GT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Pad al the data so it can be easier to treat by either adding 0sif its less the 250\n",
        "train_data=sequence.pad_sequences(train_data,MAXLEN)\n",
        "test_data=sequence.pad_sequences(test_data,MAXLEN)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K8z5uteyJ0QC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Build the Neural Networkd Model\n",
        "model=tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(VOCAB_SIZE,32), #embedding layer\n",
        "    tf.keras.layers.LSTM(32), #Long-Short Term Memory Layer\n",
        "    tf.keras.layers.Dense(1, activation=\"sigmoid\") #Dense calsiffication layer\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pQXLxrglPCYf",
        "colab_type": "code",
        "outputId": "4d6baf00-76e0-4aa9-95f5-688fe4483a18",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "model.summary()#Is a sumary of the model and its dimentions per layer the data goes through"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, None, 32)          2834688   \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 32)                8320      \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 2,843,041\n",
            "Trainable params: 2,843,041\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wh03ly1bR2LT",
        "colab_type": "code",
        "outputId": "2cd60cfe-4c7c-454e-95d6-ef70b743e1b3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "#Training the model\n",
        "model.compile(loss=\"binary_crossentropy\",optimizer=\"rmsprop\",metrics=['acc']) #Compiling the Data\n",
        "history= model.fit(train_data,train_labels,epochs=10,validation_split=0.2)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "625/625 [==============================] - 40s 63ms/step - loss: 0.4346 - acc: 0.8028 - val_loss: 0.3099 - val_acc: 0.8706\n",
            "Epoch 2/10\n",
            "625/625 [==============================] - 39s 62ms/step - loss: 0.2412 - acc: 0.9074 - val_loss: 0.2876 - val_acc: 0.8918\n",
            "Epoch 3/10\n",
            "625/625 [==============================] - 40s 64ms/step - loss: 0.1890 - acc: 0.9304 - val_loss: 0.2859 - val_acc: 0.8812\n",
            "Epoch 4/10\n",
            "625/625 [==============================] - 40s 64ms/step - loss: 0.1542 - acc: 0.9451 - val_loss: 0.3668 - val_acc: 0.8598\n",
            "Epoch 5/10\n",
            "625/625 [==============================] - 39s 63ms/step - loss: 0.1298 - acc: 0.9538 - val_loss: 0.4891 - val_acc: 0.8438\n",
            "Epoch 6/10\n",
            "625/625 [==============================] - 39s 62ms/step - loss: 0.1144 - acc: 0.9602 - val_loss: 0.3140 - val_acc: 0.8908\n",
            "Epoch 7/10\n",
            "625/625 [==============================] - 38s 61ms/step - loss: 0.0993 - acc: 0.9661 - val_loss: 0.2953 - val_acc: 0.8868\n",
            "Epoch 8/10\n",
            "625/625 [==============================] - 38s 61ms/step - loss: 0.0877 - acc: 0.9711 - val_loss: 0.3174 - val_acc: 0.8820\n",
            "Epoch 9/10\n",
            "625/625 [==============================] - 39s 62ms/step - loss: 0.0810 - acc: 0.9728 - val_loss: 0.3470 - val_acc: 0.8852\n",
            "Epoch 10/10\n",
            "625/625 [==============================] - 39s 62ms/step - loss: 0.0710 - acc: 0.9765 - val_loss: 0.3637 - val_acc: 0.8834\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d84T5X40dMri",
        "colab_type": "code",
        "outputId": "0ed04b08-127b-4549-c192-2534465732c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "results=model.evaluate(test_data,test_labels)\n",
        "print(results)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "782/782 [==============================] - 13s 16ms/step - loss: 0.4449 - acc: 0.8578\n",
            "[0.44490155577659607, 0.8578000068664551]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BqIo6GiNZcfj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "d51c7dbd-a020-4827-a91e-bac4fe80054c"
      },
      "source": [
        "\n",
        "word_index = imdb.get_word_index()\n",
        "\n",
        "def encode_text(text):\n",
        "  tokens = keras.preprocessing.text.text_to_word_sequence(text)\n",
        "  tokens = [word_index[word] if word in word_index else 0 for word in tokens]\n",
        "  return sequence.pad_sequences([tokens], MAXLEN)[0]\n",
        "\n",
        "text = \"that movie was just amazing, so amazing\"\n",
        "encoded = encode_text(text)\n",
        "print(encoded)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/text-datasets/imdb_word_index.json\n",
            "1646592/1641221 [==============================] - 0s 0us/step\n",
            "[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0  12  17  13  40 477  35 477]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PQgMLQyFeXjn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reverse_word_index ={value:key for (key,value) in word_index.items()}\n",
        "\n",
        "def decode_integers(integers):\n",
        "  PAD=0\n",
        "  text=\"\"\n",
        "  for num in integers:\n",
        "    if num!= PAD:\n",
        "      text += reverse_word_index[num] +\"\"\n",
        "\n",
        "  return text[:-1]\n",
        "  print(decode_integers(encoded))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gjVW8z2Tk8Eb",
        "colab_type": "code",
        "outputId": "54d27f93-c533-4735-b8f7-5b0b18d564b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# now time to make a prediction\n",
        "\n",
        "def predict(text):\n",
        "  encoded_text = encode_text(text)\n",
        "  pred = np.zeros((1,250))\n",
        "  pred[0] = encoded_text\n",
        "  result = model.predict(pred) \n",
        "  print(result[0])\n",
        "\n",
        "positive_review = \"That movie was! really loved it and would great watch it again because it was amazingly great\"\n",
        "predict(positive_review)\n",
        "\n",
        "negative_review = \"that movie really sucked. I hated it and wouldn't watch it again. Was one of the worst things I've ever watched\"\n",
        "predict(negative_review)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.90051997]\n",
            "[0.3288919]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}